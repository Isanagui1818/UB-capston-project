{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecciona el año de los datos que quieres cargar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estructura dataset:\n",
    "\n",
    "- Camp \tDescripció\n",
    "- last_updated \tTimestamp de l'arxiu\n",
    "- ttl \tTimeToLive de la resposta\n",
    "- data \tContenidor d'arrays d'informació d'estacions\n",
    "- stations \tArray de dades de cada estació\n",
    "- station_id \tIdentificador de l'estació\n",
    "- num_bikes_available \tNombre de bicicletes disponibles\n",
    "- num_bikes_available_types \tArray de tipus de bicicletes disponibles\n",
    "- mechanical \tNombre de bicicletes mecàniques disponibles\n",
    "- ebike \tNombre de bicicletes elèctriques disponibles\n",
    "- num_docks_available \tNombre de ancoratges disponibles\n",
    "- is_installed \tL'estació està correctament instalada (0-NO,1-SI)\n",
    "- is_renting \tL'estació està proporcionant bicicletes correctament\n",
    "- is_returning \tL'estació està ancorant bicicletes correctament\n",
    "- last_reported \tTimestamp de la informació de l'estació\n",
    "- is_charging_station \tL'estació té capacitat de càrrega de bicicletes elèctriques\n",
    "- status \tEstat de l'estació (IN_SERVICE=En servei, CLOSED=Tancada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias para usar con el código\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import plotly as fx\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tengo dos archivos de carpeta origen porque trabajo desde dos ordenadores distintos para ejecutar uno o otro dependiendo en que ordenador esté"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta de la carpeta con los archivos CSV\n",
    "carpeta_origen = 'C:/Users/TITAN OSCURO/Desktop/Datos bicing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta de la carpeta con los archivos CSV\n",
    "carpeta_origen = \"C:/Users/isana/Desktop/Datos bicing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe cargado exitosamente: Info_bicing_csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "# Leer el archivo CSV y guardarlo en un dataframe\n",
    "ruta_archivo = os.path.join(carpeta_origen, 'Informacio_Estacions_Bicing_2025.csv')\n",
    "Info_bicing_csv = pd.read_csv(ruta_archivo)\n",
    "\n",
    "# Visualizar el contenido del dataframe\n",
    "print('Dataframe cargado exitosamente: Info_bicing_csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TITAN OSCURO\\AppData\\Local\\Temp\\ipykernel_2028\\441575779.py:15: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(ruta_archivo)\n",
      "C:\\Users\\TITAN OSCURO\\AppData\\Local\\Temp\\ipykernel_2028\\441575779.py:15: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(ruta_archivo)\n",
      "C:\\Users\\TITAN OSCURO\\AppData\\Local\\Temp\\ipykernel_2028\\441575779.py:15: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(ruta_archivo)\n",
      "C:\\Users\\TITAN OSCURO\\AppData\\Local\\Temp\\ipykernel_2028\\441575779.py:15: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(ruta_archivo)\n",
      "C:\\Users\\TITAN OSCURO\\AppData\\Local\\Temp\\ipykernel_2028\\441575779.py:15: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(ruta_archivo)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos del año 2024 combinados exitosamente en un dataframe llamado 'dataframe_final_2024'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TITAN OSCURO\\AppData\\Local\\Temp\\ipykernel_2028\\441575779.py:15: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(ruta_archivo)\n",
      "C:\\Users\\TITAN OSCURO\\AppData\\Local\\Temp\\ipykernel_2028\\441575779.py:15: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(ruta_archivo)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos del año 2023 combinados exitosamente en un dataframe llamado 'dataframe_final_2023'.\n",
      "Archivos del año 2022 combinados exitosamente en un dataframe llamado 'dataframe_final_2022'.\n",
      "Archivos del año 2021 combinados exitosamente en un dataframe llamado 'dataframe_final_2021'.\n",
      "Archivos del año 2020 combinados exitosamente en un dataframe llamado 'dataframe_final_2020'.\n"
     ]
    }
   ],
   "source": [
    "# Solicitar al usuario los años a filtrar como una lista\n",
    "años_filtrar = input(\"Introduce los años que deseas filtrar, separados por comas: \").split(',')\n",
    "\n",
    "# Iterar sobre cada año en la lista\n",
    "for año_filtrar in años_filtrar:\n",
    "    # Crear una lista para almacenar los dataframes de este año\n",
    "    dataframes = []\n",
    "    \n",
    "    # Iterar sobre los archivos en la carpeta origen\n",
    "    for archivo in os.listdir(carpeta_origen):\n",
    "        # Verificar si el archivo empieza con el año indicado y es un CSV\n",
    "        if archivo.startswith(año_filtrar.strip()) and archivo.endswith(\".csv\"):\n",
    "            # Leer el archivo CSV y añadirlo a la lista de dataframes\n",
    "            ruta_archivo = os.path.join(carpeta_origen, archivo)\n",
    "            df = pd.read_csv(ruta_archivo)\n",
    "            dataframes.append(df)\n",
    "    \n",
    "    # Combinar todos los dataframes del año actual en uno solo\n",
    "    if dataframes:  # Verificar que la lista no esté vacía\n",
    "        dataframe_final = pd.concat(dataframes, ignore_index=True)\n",
    "        \n",
    "        # Crear dinámicamente una variable global con el nombre del año\n",
    "        nombre_variable = f\"dataframe_final_{año_filtrar.strip()}\"\n",
    "        globals()[nombre_variable] = dataframe_final\n",
    "        \n",
    "        print(f\"Archivos del año {año_filtrar.strip()} combinados exitosamente en un dataframe llamado '{nombre_variable}'.\")\n",
    "    else:\n",
    "        print(f\"No se encontraron archivos para el año {año_filtrar.strip()}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora puedes introducir los años en formato lista separado por , si pones todos los años (2024,2023,2022,2021,2020) la ejecución me ha tardado 5min 16,3s (no es un tiempo muy loco). También podeis ejecutar solo 1 año o varios como querais solo hay que separarlos por comas a la entrada de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- El año 2020 no tiene ningun dato NA. Tiene 46.038.633 de filas y 13 varibles.\n",
    "- El año 2021 tiene una variable más que el año anterior (traffic) y todos los valores de esta variable son NA. Tiene 52.014.085 de filas y 14 variables.\n",
    "- El año 2022 también tiene la variable (traffic) con todos los valores NA. Tiene 52.892.456 de filas y 14 varibles. Me ha tardado 1min 23s en crear el dataframe.\n",
    "- El año 2023 también tiene la variable (traffic) y tiene otra variable más (V1) ambas tiene todos los valores NA, el resto de variables tienen algunos casos NA, pero pocos si lo comparamos con el tamaño del datasaet. Tiene 49.193.646 de filas y 15 varibles. Me ha tardado 1min 18s en crear el dataframe.\n",
    "- El año 2024 no está completo, los datos solo llegan hasta mayo del 2024. También tiene las variables (traffic, V1) y ambas tienen todos los valores NA, además tiene algunos valores faltantes en el resto de variables, también muy pocos casos viendo el tamaño del dataset. Tiene 22.063.104 de filas y 15 varibles. Es el dataframe que menos tarda en cargar 52s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voy a poner código para eliminar las variables traffic y V1 en todos los dataframes que hay que eliminarlas ya que todos sus valores son faltantes. Y viendo la cantidad de datos NA los eliminaria todos en todos los datasets en vez de complicarnos la vida haciendo algún método de imputación ya que son muy pocos para el tamaño de los datasets que tenemos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminación de variables que no sirven\n",
    "dataframe_final_2021.drop(columns='traffic', inplace=True)\n",
    "dataframe_final_2022.drop(columns='traffic', inplace=True)\n",
    "dataframe_final_2023.drop(columns=['traffic','V1'], inplace=True)\n",
    "dataframe_final_2024.drop(columns=['traffic','V1'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar la columna deseada del dataframe\n",
    "dataframe_final_2020.drop(columns='nombre de columna', inplace=True) # de esta forma el cambio se hace en el data frame original\n",
    "\n",
    "# aquí borramos la columna y la guardamos en un data frame nuevo por si quieres volver atras cargar el original con todos los datos\n",
    "dataframe_final_2020_copia=dataframe_final_2020.drop(columns='nombre de columna') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminación de datos NA\n",
    "dataframe_final_2021.dropna(inplace=True)\n",
    "dataframe_final_2022.dropna(inplace=True)\n",
    "dataframe_final_2023.dropna(inplace=True)\n",
    "dataframe_final_2024.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar las dos variables timestamp en formato segundos a formato fecha. Si utilizas otro año de data frame\n",
    "dataframe_final_2020['last_reported']=pd.to_datetime(dataframe_final_2024['last_reported'], unit='s')\n",
    "dataframe_final_2020['last_updated']=pd.to_datetime(dataframe_final_2024['last_updated'], unit='s')\n",
    "\n",
    "dataframe_final_2021['last_reported']=pd.to_datetime(dataframe_final_2024['last_reported'], unit='s')\n",
    "dataframe_final_2021['last_updated']=pd.to_datetime(dataframe_final_2024['last_updated'], unit='s')\n",
    "\n",
    "dataframe_final_2022['last_reported']=pd.to_datetime(dataframe_final_2024['last_reported'], unit='s')\n",
    "dataframe_final_2022['last_updated']=pd.to_datetime(dataframe_final_2024['last_updated'], unit='s')\n",
    "\n",
    "dataframe_final_2023['last_reported']=pd.to_datetime(dataframe_final_2024['last_reported'], unit='s')\n",
    "dataframe_final_2023['last_updated']=pd.to_datetime(dataframe_final_2024['last_updated'], unit='s')\n",
    "\n",
    "dataframe_final_2024['last_reported']=pd.to_datetime(dataframe_final_2024['last_reported'], unit='s')\n",
    "dataframe_final_2024['last_updated']=pd.to_datetime(dataframe_final_2024['last_updated'], unit='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset sobre información de las estaciones de bicing:\n",
    "- La variable (rental_uris) tienen todos los valores NA y la variable (is_valet_station) así que mejor eliminar ambas variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminación de variables que no sirven\n",
    "Info_bicing_csv.drop(columns='rental_uris', inplace=True)\n",
    "Info_bicing_csv.drop(columns='is_valet_station', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta aquí ya hay un procesado previo que deja los datos listos para ser visualizados de forma sencilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 516 entries, 0 to 515\n",
      "Data columns (total 14 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   station_id              516 non-null    int64  \n",
      " 1   name                    516 non-null    object \n",
      " 2   physical_configuration  516 non-null    object \n",
      " 3   lat                     516 non-null    float64\n",
      " 4   lon                     516 non-null    float64\n",
      " 5   altitude                506 non-null    float64\n",
      " 6   address                 516 non-null    object \n",
      " 7   cross_street            514 non-null    object \n",
      " 8   post_code               514 non-null    float64\n",
      " 9   capacity                516 non-null    int64  \n",
      " 10  is_charging_station     516 non-null    bool   \n",
      " 11  short_name              516 non-null    int64  \n",
      " 12  nearby_distance         516 non-null    float64\n",
      " 13  _ride_code_support      516 non-null    bool   \n",
      "dtypes: bool(2), float64(5), int64(3), object(4)\n",
      "memory usage: 49.5+ KB\n"
     ]
    }
   ],
   "source": [
    "Info_bicing_csv.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "station_id                 0\n",
       "name                       0\n",
       "physical_configuration     0\n",
       "lat                        0\n",
       "lon                        0\n",
       "altitude                  10\n",
       "address                    0\n",
       "cross_street               2\n",
       "post_code                  2\n",
       "capacity                   0\n",
       "is_charging_station        0\n",
       "short_name                 0\n",
       "nearby_distance            0\n",
       "_ride_code_support         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Info_bicing_csv.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cuestiones de interés sobre los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enlaces de interés\n",
    "- https://opendata-ajuntament.barcelona.cat/es/\n",
    "- https://chat.deepseek.com/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
